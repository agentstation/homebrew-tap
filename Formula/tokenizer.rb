# typed: false
# frozen_string_literal: true

# This file was generated by GoReleaser. DO NOT EDIT.
class Tokenizer < Formula
  desc "High-performance tokenizer implementations in Go with unified CLI"
  homepage "https://github.com/agentstation/tokenizer"
  version "0.0.4"
  license "MIT"

  depends_on "go" => :build

  on_macos do
    if Hardware::CPU.intel?
      url "https://github.com/agentstation/tokenizer/releases/download/v0.0.4/tokenizer_0.0.4_darwin_x86_64.tar.gz", using: CurlDownloadStrategy
      sha256 "5fdab00675ebd7e7f46e99ea3d203d46499729b69830fe3c7e92de3058775d03"

      def install
        if build.bottle?
          bin.install "tokenizer"
        else
          # Build from source with version information
          # Note: buildDate is the actual build time (now), not the commit date
          ldflags = %W[
            -s -w
            -X main.version=#{version}
            -X main.commit=1c64bee
            -X main.buildDate=#{Time.now.utc.strftime("%Y-%m-%dT%H:%M:%SZ")}
            -X main.goVersion=#{Formula["go"].version}
            -X main.builtBy=homebrew
          ]
          system "go", "build", *std_go_args(ldflags: ldflags), "./cmd/tokenizer"
        end

        # Install documentation
        doc.install "README.md", "LICENSE", "CLAUDE.md"
        doc.install "llama3/README.md" => "llama3-README.md"
        doc.install "llama3/IMPLEMENTATION.md" => "llama3-IMPLEMENTATION.md"

        # Install examples if they exist
        if Dir.exist?("examples")
          pkgshare.install "examples"
        end
      end
    end
    if Hardware::CPU.arm?
      url "https://github.com/agentstation/tokenizer/releases/download/v0.0.4/tokenizer_0.0.4_darwin_arm64.tar.gz", using: CurlDownloadStrategy
      sha256 "981d58713ee6271e29ce5795f30f21bfb5a6d39c8fa721e109bcd8574c853a21"

      def install
        if build.bottle?
          bin.install "tokenizer"
        else
          # Build from source with version information
          # Note: buildDate is the actual build time (now), not the commit date
          ldflags = %W[
            -s -w
            -X main.version=#{version}
            -X main.commit=1c64bee
            -X main.buildDate=#{Time.now.utc.strftime("%Y-%m-%dT%H:%M:%SZ")}
            -X main.goVersion=#{Formula["go"].version}
            -X main.builtBy=homebrew
          ]
          system "go", "build", *std_go_args(ldflags: ldflags), "./cmd/tokenizer"
        end

        # Install documentation
        doc.install "README.md", "LICENSE", "CLAUDE.md"
        doc.install "llama3/README.md" => "llama3-README.md"
        doc.install "llama3/IMPLEMENTATION.md" => "llama3-IMPLEMENTATION.md"

        # Install examples if they exist
        if Dir.exist?("examples")
          pkgshare.install "examples"
        end
      end
    end
  end

  on_linux do
    if Hardware::CPU.intel? and Hardware::CPU.is_64_bit?
      url "https://github.com/agentstation/tokenizer/releases/download/v0.0.4/tokenizer_0.0.4_linux_x86_64.tar.gz", using: CurlDownloadStrategy
      sha256 "1f802f554ddb7a613db997204f7bee32a628fb402a35c3b005fcb7c5df83361a"
      def install
        if build.bottle?
          bin.install "tokenizer"
        else
          # Build from source with version information
          # Note: buildDate is the actual build time (now), not the commit date
          ldflags = %W[
            -s -w
            -X main.version=#{version}
            -X main.commit=1c64bee
            -X main.buildDate=#{Time.now.utc.strftime("%Y-%m-%dT%H:%M:%SZ")}
            -X main.goVersion=#{Formula["go"].version}
            -X main.builtBy=homebrew
          ]
          system "go", "build", *std_go_args(ldflags: ldflags), "./cmd/tokenizer"
        end

        # Install documentation
        doc.install "README.md", "LICENSE", "CLAUDE.md"
        doc.install "llama3/README.md" => "llama3-README.md"
        doc.install "llama3/IMPLEMENTATION.md" => "llama3-IMPLEMENTATION.md"

        # Install examples if they exist
        if Dir.exist?("examples")
          pkgshare.install "examples"
        end
      end
    end
    if Hardware::CPU.arm? and !Hardware::CPU.is_64_bit?
      url "https://github.com/agentstation/tokenizer/releases/download/v0.0.4/tokenizer_0.0.4_linux_armv6.tar.gz", using: CurlDownloadStrategy
      sha256 "5512a5779edf3be4fea7b9939b53606ff485697c3d84feacc3a3723133e89181"
      def install
        if build.bottle?
          bin.install "tokenizer"
        else
          # Build from source with version information
          # Note: buildDate is the actual build time (now), not the commit date
          ldflags = %W[
            -s -w
            -X main.version=#{version}
            -X main.commit=1c64bee
            -X main.buildDate=#{Time.now.utc.strftime("%Y-%m-%dT%H:%M:%SZ")}
            -X main.goVersion=#{Formula["go"].version}
            -X main.builtBy=homebrew
          ]
          system "go", "build", *std_go_args(ldflags: ldflags), "./cmd/tokenizer"
        end

        # Install documentation
        doc.install "README.md", "LICENSE", "CLAUDE.md"
        doc.install "llama3/README.md" => "llama3-README.md"
        doc.install "llama3/IMPLEMENTATION.md" => "llama3-IMPLEMENTATION.md"

        # Install examples if they exist
        if Dir.exist?("examples")
          pkgshare.install "examples"
        end
      end
    end
    if Hardware::CPU.arm? and Hardware::CPU.is_64_bit?
      url "https://github.com/agentstation/tokenizer/releases/download/v0.0.4/tokenizer_0.0.4_linux_arm64.tar.gz", using: CurlDownloadStrategy
      sha256 "11062b05628de586aa93c8941633d9781ec1a250768461bfbf63d036b19ce42c"
      def install
        if build.bottle?
          bin.install "tokenizer"
        else
          # Build from source with version information
          # Note: buildDate is the actual build time (now), not the commit date
          ldflags = %W[
            -s -w
            -X main.version=#{version}
            -X main.commit=1c64bee
            -X main.buildDate=#{Time.now.utc.strftime("%Y-%m-%dT%H:%M:%SZ")}
            -X main.goVersion=#{Formula["go"].version}
            -X main.builtBy=homebrew
          ]
          system "go", "build", *std_go_args(ldflags: ldflags), "./cmd/tokenizer"
        end

        # Install documentation
        doc.install "README.md", "LICENSE", "CLAUDE.md"
        doc.install "llama3/README.md" => "llama3-README.md"
        doc.install "llama3/IMPLEMENTATION.md" => "llama3-IMPLEMENTATION.md"

        # Install examples if they exist
        if Dir.exist?("examples")
          pkgshare.install "examples"
        end
      end
    end
  end

  def caveats
    <<~EOS
      Tokenizer has been installed! ðŸš€

      Quick start:
        tokenizer llama3 encode "Hello, world!"     # Encode text to tokens
        tokenizer llama3 decode 128000 9906 128001  # Decode tokens to text
        tokenizer llama3 info                       # Show tokenizer info
        tokenizer --help                            # Show all commands

      Documentation: https://github.com/agentstation/tokenizer
    EOS
  end

  test do
    # Test version command
    output = shell_output("#{bin}/tokenizer version")
    assert_match version.to_s, output
    assert_match "commit:", output
    assert_match "built:", output
    assert_match "go version:", output

    # Test help output
    assert_match "Usage:", shell_output("#{bin}/tokenizer --help")
    assert_match "Available Commands:", shell_output("#{bin}/tokenizer --help")

    # Test llama3 subcommand
    assert_match "llama3", shell_output("#{bin}/tokenizer --help")
    assert_match "encode", shell_output("#{bin}/tokenizer llama3 --help")

    # Test encoding
    output = shell_output("#{bin}/tokenizer llama3 encode 'Hello, world!'")
    assert_match "128000", output # begin_of_text token
    assert_match "9906", output   # "Hello" token
    assert_match "128001", output # end_of_text token

    # Test decoding
    output = shell_output("#{bin}/tokenizer llama3 decode 128000 9906 11 1917 0 128001")
    assert_match "Hello", output
    assert_match "world", output

    # Test info command
    output = shell_output("#{bin}/tokenizer llama3 info")
    assert_match "Vocabulary Size: 128256", output
    assert_match "Regular Tokens: 128000", output
    assert_match "Special Tokens: 256", output

    # Test piping
    output = pipe_output("#{bin}/tokenizer llama3 encode", "Test input")
    assert_match "128000", output # begin_of_text token
  end
end
